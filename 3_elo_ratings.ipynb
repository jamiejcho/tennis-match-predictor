{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8efc849",
   "metadata": {},
   "source": [
    "## Notebook 3: Advanced Feature Engineering - Elo Ratings\n",
    "\n",
    "In Notebook 2, we calculated standard tennis statistics (z.B., serve %, recent form). In this notebook, we introduce Elo Ratings, a system originally designed for Chess but highly predictive in tennis.\n",
    "\n",
    "### What is Elo?\n",
    "Originally designed for Chess, Elo is a system that calculates the relative skill levels of players in zero-sum games.\n",
    "- ATP Rankings vs Elo:\n",
    "    - ATP Rankings are based on how far you go in a tournament. \n",
    "    - Elo is based on who you beat. \n",
    "    - Hence, beating the World No. 1 yields more points than beating the World No. 100.\n",
    "- The Zero-Sum Rule: \n",
    "    - If Player A gains 10 points, Player B loses 10 points. \n",
    "    - This keeps the system slightly inflation-proof.\n",
    "\n",
    "### Our Approach\n",
    "We maintain two different types of Elo ratings.\n",
    "- Overall Elo: A single rating representing general strength.\n",
    "- Surface Elo: Separate ratings for Hard, Clay, and Grass. This is crucial for tennis (z.B., Nadal's Clay rating is historically much higher than his Grass rating).\n",
    "\n",
    "In this notebook, we load two datasets:\n",
    "- df_clean: The raw history (1 row per match). We use this to calculate Elo to avoid double-counting.\n",
    "- df_featured: The training data (2 rows per match). We will merge the calculated ratings into this file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92c6d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Clean Data (Calculation Source): 198,055 matches\n",
      "Loaded Featured Data (Merge Target): 396,110 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Display settings to see all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 1. Load the CLEAN dataset (1 row per match)\n",
    "# We calculate the running Elo history on this file because it represents the timeline perfectly.\n",
    "# Using the \"doubled\" dataset would cause us to update the ratings twice per match (bad).\n",
    "df_clean = pd.read_csv('master_data_cleaned.csv')\n",
    "df_clean['tourney_date'] = pd.to_datetime(df_clean['tourney_date'])\n",
    "\n",
    "# Sort chronologically\n",
    "# We need to calculate ratings in the correct order of time.\n",
    "# Added 'tourney_id' to the sort for perfect deterministic ordering\n",
    "df_clean = df_clean.sort_values(by=['tourney_date', 'tourney_id', 'match_num']).reset_index(drop=True)\n",
    "\n",
    "# 2. Load the FEATURED dataset (2 rows per match)\n",
    "# This is our target. We will deposit the calculated ratings into this file at the end.\n",
    "df_featured = pd.read_csv('master_data_featured.csv')\n",
    "df_featured['tourney_date'] = pd.to_datetime(df_featured['tourney_date'])\n",
    "\n",
    "print(f\"Loaded Clean Data (Calculation Source): {len(df_clean):,} matches\")\n",
    "print(f\"Loaded Featured Data (Merge Target): {len(df_featured):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a8024",
   "metadata": {},
   "source": [
    "## 2. The Elo Engine\n",
    "Here we define the EloTracker class. This \"engine\" handles the math.\n",
    "\n",
    "### The Math\n",
    "The formula for updating a player's rating is:\n",
    "$$R_{new} = R_{old} + K \\times (Actual - Expected)$$\n",
    "where:\n",
    "- $R_{old}$: The player's current rating (starts at 1500).\n",
    "- $K$ (K-factor): The \"weight\" of the match.\n",
    "    - Grand Slams ($K=50$): Big updates. A win here matters significantly.\n",
    "    - Futures ($K=20$): Small updates. A win here is less impactful.\n",
    "- $Expected$: The probability of winning, calculated using the difference in ratings.\n",
    "    - If Djokovic (Rating 2500) plays a Qualifier (Rating 1500), Djokovic's expected score is near 1.0 (99%).\n",
    "    - If he wins, he gains very few points: $Actual (1) - Expected (0.99) = 0.01$.\n",
    "    - If he loses, he Elo crashes: $Actual (0) - Expected (0.99) = -0.99$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1452c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EloTracker:\n",
    "    def __init__(self, start_rating=1500):\n",
    "        # A dictionary to store the current rating of every player ID\n",
    "        # Format: {'player_id': 1560.5, 'another_id': 1490.2}\n",
    "        self.ratings = {} \n",
    "        self.start_rating = start_rating\n",
    "        \n",
    "    def get_rating(self, player_id):\n",
    "        # Return the player's rating. \n",
    "        # If they are new, return the starting 1500.\n",
    "        return self.ratings.get(player_id, self.start_rating)\n",
    "    \n",
    "    def update_ratings(self, winner_id, loser_id, k_factor):\n",
    "        # 1. Get current ratings (BEFORE the match)\n",
    "        r_winner = self.get_rating(winner_id)\n",
    "        r_loser = self.get_rating(loser_id)\n",
    "        \n",
    "        # 2. Calculate Expected Score (win probability)\n",
    "        # Formula: 1 / (1 + 10^((OpponentRating - MyRating) / 400))\n",
    "        # This is the standard logistic curve used in chess.\n",
    "        expected_winner = 1 / (1 + 10 ** ((r_loser - r_winner) / 400))\n",
    "        expected_loser = 1 / (1 + 10 ** ((r_winner - r_loser) / 400))\n",
    "        \n",
    "        # 3. Calculate New Ratings\n",
    "        # Winner: Actual score is 1.0\n",
    "        new_r_winner = r_winner + k_factor * (1 - expected_winner)\n",
    "        \n",
    "        # Loser: Actual score is 0.0\n",
    "        new_r_loser = r_loser + k_factor * (0 - expected_loser)\n",
    "        \n",
    "        # 4. Save New Ratings to the dictionary\n",
    "        self.ratings[winner_id] = new_r_winner\n",
    "        self.ratings[loser_id] = new_r_loser\n",
    "        \n",
    "        # 5. Return the PRE-match ratings\n",
    "        # Important: We return r_winner, NOT new_r_winner.\n",
    "        # Reason: For prediction, we only know the rating BEFORE the match happens.\n",
    "        return r_winner, r_loser\n",
    "\n",
    "# Define K-Factors (wweight of the match)\n",
    "# Grand Slams impact your rating more than Challengers.\n",
    "K_MAP = {\n",
    "    'G': 50,      # Grand Slam (Highest weight)\n",
    "    'F': 45,      # Tour Finals\n",
    "    'M': 40,      # Masters 1000\n",
    "    'A': 35,      # ATP 500/250\n",
    "    'D': 30,      # Davis Cup\n",
    "    'C': 25,      # Challengers\n",
    "    'S': 20,      # Futures (Lowest weight)\n",
    "    'Unknown': 30 # Fallback\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c7660",
   "metadata": {},
   "source": [
    "## 3. Calculating Overall Elo\n",
    "Now we run the history simulation. We iterate through 150,000+ matches chronologically.\n",
    "\n",
    "Loop Logic:\n",
    "1. Look at Match $N$.\n",
    "2. Retrieve the current ratings of the Winner and Loser.\n",
    "3. Store them in our list (to add to the dataframe later).\n",
    "4. Update the EloTracker so the ratings are correct for Match $N+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f03636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Overall Elo history (1968-2026) ...\n",
      "Overall Elo calculated in 3.09 seconds.\n",
      "\n",
      "Overall Elo ratings from the last 3 matches before AO 2026:\n",
      "       tourney_name tourney_date   winner_name   winner_elo  \\\n",
      "198052     Adelaide   2026-01-16   Ugo Humbert  1773.060491   \n",
      "198053     Auckland   2026-01-17  Jakub Mensik  1786.858666   \n",
      "198054     Adelaide   2026-01-17  Tomas Machac  1726.534933   \n",
      "\n",
      "                         loser_name    loser_elo  \n",
      "198052  Alejandro Davidovich Fokina  1812.581783  \n",
      "198053               Sebastian Baez  1676.588333  \n",
      "198054                  Ugo Humbert  1789.759441  \n"
     ]
    }
   ],
   "source": [
    "elo_tracker = EloTracker(start_rating=1500)\n",
    "winner_elos = []\n",
    "loser_elos = []\n",
    "\n",
    "print(\"Calculating Overall Elo history (1968-2026) ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate through each match in chronological order\n",
    "for idx, row in df_clean.iterrows():\n",
    "    w_id = row['winner_id']\n",
    "    l_id = row['loser_id']\n",
    "    level = row['tourney_level']\n",
    "    \n",
    "    # 1. Determine the K-Factor for this specific match\n",
    "    k = K_MAP.get(level, 30)  # Default to 30 if level is missing\n",
    "    \n",
    "    # 2. Update ratings and capture the values entering the match\n",
    "    w_elo, l_elo = elo_tracker.update_ratings(w_id, l_id, k)\n",
    "    \n",
    "    winner_elos.append(w_elo)\n",
    "    loser_elos.append(l_elo)\n",
    "\n",
    "# Add the calculated lists back into the clean dataframe\n",
    "df_clean['winner_elo'] = winner_elos\n",
    "df_clean['loser_elo'] = loser_elos\n",
    "\n",
    "print(f\"Overall Elo calculated in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "# Quick Check:\n",
    "print(f\"\\nOverall Elo ratings from the last 3 matches before AO 2026:\")\n",
    "print(df_clean[['tourney_name','tourney_date', 'winner_name', 'winner_elo', 'loser_name', 'loser_elo']].tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9dfbe",
   "metadata": {},
   "source": [
    "## 4. Calculating Surface-Specific Elo\n",
    "\n",
    "A generic rating doesn't capture surface specialists (z.B., Nadal on Clay vs. Nadal on Indoor Hard). We address this limitation by running three independent Elo simulations in parallel.\n",
    "\n",
    "- Hard Court Tracker: Only updates when surface == 'Hard'.\n",
    "- Clay Court Tracker: Only updates when surface == 'Clay'.\n",
    "- Grass Court Tracker: Only updates when surface == 'Grass'.\n",
    "\n",
    "Note on 'Carpet': This surface is obsolete. For simplicity, we track it separately, but it won't be heavily used in modern prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aba57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Surface-Specific Elo history (1968-2026) ...\n",
      "Surface Elo calculated in 6.53 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a separate dictionary for each surface\n",
    "surface_trackers = {\n",
    "    'Hard': EloTracker(),\n",
    "    'Clay': EloTracker(),\n",
    "    'Grass': EloTracker(),\n",
    "    'Carpet': EloTracker(),\n",
    "    'Unknown': EloTracker()\n",
    "}\n",
    "\n",
    "winner_surface_elos = []\n",
    "loser_surface_elos = []\n",
    "\n",
    "print(\"Calculating Surface-Specific Elo history (1968-2026) ...\")\n",
    "\n",
    "# Iterate through each match in chronological order\n",
    "for idx, row in df_clean.iterrows():\n",
    "    w_id = row['winner_id']\n",
    "    l_id = row['loser_id']\n",
    "    surface = row['surface']\n",
    "    level = row['tourney_level']\n",
    "    k = K_MAP.get(level, 35)\n",
    "    \n",
    "    # 1. Identify which tracker to use\n",
    "    if surface not in surface_trackers:\n",
    "        target_tracker = surface_trackers['Unknown']\n",
    "    else:\n",
    "        target_tracker = surface_trackers[surface]\n",
    "    \n",
    "    # 2. Update ONLY that specific tracker\n",
    "    # The 'Clay' tracker doesn't care if you lost a match on 'Grass'.\n",
    "    w_elo, l_elo = target_tracker.update_ratings(w_id, l_id, k)\n",
    "    \n",
    "    winner_surface_elos.append(w_elo)\n",
    "    loser_surface_elos.append(l_elo)\n",
    "\n",
    "# Add to the clean dataframe\n",
    "df_clean['winner_surface_elo'] = winner_surface_elos\n",
    "df_clean['loser_surface_elo'] = loser_surface_elos\n",
    "\n",
    "print(f\"Surface Elo calculated in {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c2c6f",
   "metadata": {},
   "source": [
    "## 5. Merging Elo into the Training Data\n",
    "\n",
    "We now have the ratings, but they are in the wrong format (df_clean has 1 row per match). We need to move them to df_featured (2 rows per match).\n",
    "\n",
    "Merge Logic: \n",
    "1. Extract: We take the Elo columns from df_clean.\n",
    "1. Join: We merge df_clean and df_featured using tourney_date and match_num as a unique identifier.\n",
    "1. Distribute:\n",
    "    - If target == 1 (P1 Won): We assign winner_elo to P1 and loser_elo to P2.\n",
    "    - If target == 0 (P1 Lost): We assign loser_elo to P1 and winner_elo to P2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa44455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Merge is clean. Row counts match.\n",
      "SUCCESS: Elo feature engineering complete.\n",
      "Final dataset shape: (396110, 32)\n",
      "Saved to: master_data_final.csv\n",
      "\n",
      "Djokovic's Elo rating in late 2023:\n",
      "                          tourney_name tourney_date         p1_name  \\\n",
      "90963                      Tour Finals   2023-11-13  Novak Djokovic   \n",
      "90964                      Tour Finals   2023-11-13  Novak Djokovic   \n",
      "90965                      Tour Finals   2023-11-13  Novak Djokovic   \n",
      "90966  Davis Cup Finals QF: SRB vs GBR   2023-11-23  Novak Djokovic   \n",
      "90967  Davis Cup Finals SF: ITA vs SRB   2023-11-25  Novak Djokovic   \n",
      "\n",
      "            p1_elo  p1_surface_elo  \n",
      "90963  2329.052087     2316.535254  \n",
      "90964  2292.108507     2280.263135  \n",
      "90965  2304.060299     2288.352485  \n",
      "90966  2315.728410     2300.974494  \n",
      "90967  2316.415782     2301.698320  \n"
     ]
    }
   ],
   "source": [
    "# 1. Create a \"lookup key\" to join the datasets\n",
    "# We use tourney_id+match_num as unique ID (torney_name is not unique)\n",
    "# We can simply merge based on the index if we sort them identically, but a merge key is safer.\n",
    "# Now, subset the Elo data to just what we need to merge\n",
    "elo_features = df_clean[['tourney_id', 'match_num', 'winner_id', 'loser_id', \n",
    "                         'winner_elo', 'loser_elo', \n",
    "                         'winner_surface_elo', 'loser_surface_elo']].copy()\n",
    "\n",
    "# Critical FIX: Ensure the Elo Source is Unique\n",
    "# We drop duplicates based on the merge keys to prevent row explosion.\n",
    "elo_features = elo_features.drop_duplicates(subset=['tourney_id', 'match_num'])\n",
    "\n",
    "# 2. Merge onto the featured dataset\n",
    "# Since df_featured has P1 and P2, we need to know who is who. \n",
    "# In df_featured, 'target=1' means P1 is Winner. 'target=0' means P1 is Loser.\n",
    "# Strategy: Merge on (tourney_date, match_num), then assign p1_elo based on target.\n",
    "df_final = pd.merge(df_featured, elo_features, on=['tourney_id', 'match_num'], how='left')\n",
    "\n",
    "# 3. Assign Elo to P1 and P2\n",
    "# If target == 1 (P1 Won): P1 is Winner, P2 is Loser\n",
    "# If target == 0 (P1 Lost): P1 is Loser, P2 is Winner\n",
    "conditions = [df_final['target'] == 1, df_final['target'] == 0]\n",
    "\n",
    "# Overall Elo\n",
    "# If P1 Won: P1 gets WinnerElo, P2 gets LoserElo\n",
    "# If P1 Lost: P1 gets LoserElo, P2 gets WinnerElo\n",
    "choices_p1 = [df_final['winner_elo'], df_final['loser_elo']]\n",
    "choices_p2 = [df_final['loser_elo'], df_final['winner_elo']]\n",
    "df_final['p1_elo'] = np.select(conditions, choices_p1)\n",
    "df_final['p2_elo'] = np.select(conditions, choices_p2)\n",
    "\n",
    "# Same for Surface Elo\n",
    "choices_p1_surf = [df_final['winner_surface_elo'], df_final['loser_surface_elo']]\n",
    "choices_p2_surf = [df_final['loser_surface_elo'], df_final['winner_surface_elo']]\n",
    "df_final['p1_surface_elo'] = np.select(conditions, choices_p1_surf)\n",
    "df_final['p2_surface_elo'] = np.select(conditions, choices_p2_surf)\n",
    "\n",
    "# 4. Cleanup\n",
    "# Remove the temporary \"winner_elo\" columns we just merged\n",
    "df_final = df_final.drop(columns=['winner_id', 'loser_id', 'winner_elo', 'loser_elo', \n",
    "                                  'winner_surface_elo', 'loser_surface_elo'])\n",
    "\n",
    "# 5. Save the final dataset\n",
    "output_file = 'master_data_final.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "# Merge sanity check: Check row counts prior to and after merge\n",
    "if len(df_final) == len(df_featured):\n",
    "    print(\"SUCCESS: Merge is clean. Row counts match.\")\n",
    "else:\n",
    "    print(f\"WARNING: Row count mismatch! ({len(df_featured)} vs {len(df_final)})\")\n",
    "\n",
    "print(\"SUCCESS: Elo feature engineering complete.\")\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "\n",
    "# Quick check: Djkovic's Elo in late 2023\n",
    "print(\"\\nDjokovic's Elo rating in late 2023:\")\n",
    "mask = (df_final['p1_name'] == 'Novak Djokovic') & (df_final['tourney_date'].dt.year == 2023)\n",
    "cols = ['tourney_name', 'tourney_date', 'p1_name', 'p1_elo', 'p1_surface_elo']\n",
    "print(df_final[mask][cols].tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
